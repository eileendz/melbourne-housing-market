{
  "dense_unit1": 2048,
  "dropout": 0.2,
  "dense_unit2": 128,
  "learning_rate": 1e-05,
  "epoch": 200,
  "batch_size": 64,
  "activation": "relu"
}
