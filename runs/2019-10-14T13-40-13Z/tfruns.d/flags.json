{
  "dense_unit1": 1024,
  "dropout": 0,
  "dense_unit2": 1024,
  "dense_unit3": 512,
  "learning_rate": 0.001,
  "epoch": 500,
  "batch_size": 64,
  "activation": "relu"
}
