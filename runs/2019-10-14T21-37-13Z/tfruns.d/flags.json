{
  "dense_unit1": 512,
  "dropout": 0.2,
  "dense_unit2": 256,
  "dense_unit3": 256,
  "dense_unit4": 256,
  "learning_rate": 0.001,
  "epoch": 500,
  "batch_size": 128,
  "activation": "relu"
}
