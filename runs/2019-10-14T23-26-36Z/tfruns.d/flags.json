{
  "dense_unit1": 1024,
  "dropout": 0.2,
  "dense_unit2": 512,
  "dense_unit3": 128,
  "dense_unit4": 128,
  "learning_rate": 0.001,
  "epoch": 500,
  "batch_size": 128,
  "activation": "relu"
}
