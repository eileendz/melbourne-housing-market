{
  "dense_unit1": 2048,
  "dropout": 0.2,
  "dense_unit2": 1024,
  "dense_unit3": 256,
  "learning_rate": 0.001,
  "epoch": 500,
  "batch_size": 64,
  "activation": "relu"
}
